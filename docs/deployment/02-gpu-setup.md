# Ollama Docker GPU é…ç½®èªªæ˜

## ğŸ¯ é…ç½®ç›®æ¨™

ç‚º Ollama Docker å®¹å™¨å•Ÿç”¨ NVIDIA GPU åŠ é€Ÿï¼Œæå‡å¤§å‹èªè¨€æ¨¡å‹çš„æ¨ç†æ•ˆèƒ½ã€‚

## ğŸ”§ ç³»çµ±è¦æ±‚

### ç¡¬é«”è¦æ±‚
- NVIDIA GPUï¼ˆå·²ç¢ºèªï¼šNVIDIA GeForce RTX 2060ï¼‰
- è¶³å¤ çš„ GPU è¨˜æ†¶é«”ï¼ˆå»ºè­° 4GB+ï¼‰

### è»Ÿé«”è¦æ±‚
- Docker 28.1.1+
- NVIDIA é©…å‹•ç¨‹å¼ 576.28+
- CUDA 12.9+
- NVIDIA Container Toolkit 1.17.8+

## ğŸ“‹ é…ç½®æ­¥é©Ÿ

### 1. æª¢æŸ¥ç³»çµ±ç’°å¢ƒ

```bash
# æª¢æŸ¥ Docker ç‰ˆæœ¬
docker --version

# æª¢æŸ¥ NVIDIA é©…å‹•ç¨‹å¼
nvidia-smi

# æª¢æŸ¥ NVIDIA Container Toolkit
dpkg -l | grep nvidia-container-toolkit
```

### 2. é…ç½® Docker ä½¿ç”¨ NVIDIA é©…å‹•

```bash
# é…ç½® Docker ä½¿ç”¨ NVIDIA é©…å‹•
sudo nvidia-ctk runtime configure --runtime=docker

# é‡å•Ÿ Docker æœå‹™ï¼ˆå¦‚æœéœ€è¦ï¼‰
sudo systemctl restart docker
```

### 3. æ›´æ–° Docker Compose é…ç½®

åœ¨ `docker-compose.yml` ä¸­ç‚º Ollama æœå‹™æ·»åŠ  GPU æ”¯æ´ï¼š

```yaml
ollama:
  image: ollama/ollama
  ports:
    - "11434:11434"
  volumes:
    - ollama_data:/root/.ollama
  container_name: ai-cyber-dataset-review-ollama
  networks:
    - app-network
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
```

### 4. é‡æ–°å•Ÿå‹•æœå‹™

```bash
# åœæ­¢ç¾æœ‰å®¹å™¨
docker-compose down

# é‡æ–°å•Ÿå‹•æœå‹™
docker-compose up -d
```

## âœ… é©—è­‰é…ç½®

### 1. æª¢æŸ¥ Ollama æ—¥èªŒ

```bash
docker logs ai-cyber-dataset-review-ollama
```

æˆåŠŸé…ç½®å¾Œæ‡‰è©²çœ‹åˆ°ï¼š
```
msg="inference compute" id=GPU-93fd781b-3649-96a3-11fd-c6d4c2ae55e6 
library=cuda variant=v12 compute=7.5 driver=12.9 
name="NVIDIA GeForce RTX 2060" total="6.0 GiB" available="5.0 GiB"
```

### 2. æ¸¬è©¦ GPU åŠ é€Ÿ

```bash
# ä¸‹è¼‰æ¨¡å‹
docker exec ai-cyber-dataset-review-ollama ollama pull llama3

# é‹è¡Œæ¨¡å‹æ¸¬è©¦
docker exec -it ai-cyber-dataset-review-ollama ollama run llama3
```

## ğŸš€ æ•ˆèƒ½æå‡

### GPU åŠ é€Ÿæ•ˆæœ
- **æ¨ç†é€Ÿåº¦**ï¼šç›¸æ¯” CPU æå‡ 5-10 å€
- **ä¸¦ç™¼è™•ç†**ï¼šæ”¯æ´å¤šå€‹è«‹æ±‚åŒæ™‚è™•ç†
- **è¨˜æ†¶é«”æ•ˆç‡**ï¼šGPU è¨˜æ†¶é«”ç›´æ¥è¨ªå•ï¼Œæ¸›å°‘æ•¸æ“šå‚³è¼¸

### æ”¯æ´çš„æ¨¡å‹
- Llama ç³»åˆ—æ¨¡å‹
- Mistral ç³»åˆ—æ¨¡å‹
- Code Llama ç³»åˆ—æ¨¡å‹
- å…¶ä»–æ”¯æ´ CUDA çš„æ¨¡å‹

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. GPU æœªè¢«è­˜åˆ¥
```bash
# æª¢æŸ¥ NVIDIA Container Toolkit å®‰è£
dpkg -l | grep nvidia-container-toolkit

# é‡æ–°é…ç½® Docker
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
```

#### 2. æ¬Šé™å•é¡Œ
```bash
# æª¢æŸ¥ Docker ç”¨æˆ¶çµ„
groups $USER

# æ·»åŠ ç”¨æˆ¶åˆ° docker çµ„
sudo usermod -aG docker $USER
```

#### 3. è¨˜æ†¶é«”ä¸è¶³
```bash
# æª¢æŸ¥ GPU è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
nvidia-smi

# èª¿æ•´æ¨¡å‹å¤§å°æˆ–ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬
docker exec ai-cyber-dataset-review-ollama ollama pull llama3:8b
```

## ğŸ“Š ç›£æ§ GPU ä½¿ç”¨

### å³æ™‚ç›£æ§
```bash
# ç›£æ§ GPU ä½¿ç”¨æƒ…æ³
watch -n 1 nvidia-smi

# ç›£æ§å®¹å™¨ GPU ä½¿ç”¨
docker stats ai-cyber-dataset-review-ollama
```

### æ—¥èªŒç›£æ§
```bash
# æŸ¥çœ‹ Ollama è©³ç´°æ—¥èªŒ
docker logs -f ai-cyber-dataset-review-ollama
```

## ğŸ¯ æœ€ä½³å¯¦è¸

### 1. æ¨¡å‹é¸æ“‡
- æ ¹æ“š GPU è¨˜æ†¶é«”é¸æ“‡åˆé©çš„æ¨¡å‹å¤§å°
- è€ƒæ…®ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬ä»¥ç¯€çœè¨˜æ†¶é«”

### 2. è³‡æºç®¡ç†
- ç›£æ§ GPU è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
- é¿å…åŒæ™‚é‹è¡Œå¤šå€‹å¤§å‹æ¨¡å‹

### 3. æ•ˆèƒ½å„ªåŒ–
- ä½¿ç”¨é©ç•¶çš„æ‰¹æ¬¡å¤§å°
- èª¿æ•´ä¸Šä¸‹æ–‡é•·åº¦ä»¥å¹³è¡¡æ•ˆèƒ½å’Œè¨˜æ†¶é«”

## ğŸ“ é…ç½®æª”æ¡ˆ

### ç•¶å‰é…ç½®ç‹€æ…‹
- âœ… NVIDIA é©…å‹•ç¨‹å¼ï¼š576.28
- âœ… CUDA ç‰ˆæœ¬ï¼š12.9
- âœ… NVIDIA Container Toolkitï¼š1.17.8
- âœ… Docker ç‰ˆæœ¬ï¼š28.1.1
- âœ… GPUï¼šNVIDIA GeForce RTX 2060 (6GB)

### ç’°å¢ƒè®Šæ•¸
```bash
# Ollama ç’°å¢ƒè®Šæ•¸
OLLAMA_HOST=http://0.0.0.0:11434
OLLAMA_ORIGINS=[http://localhost https://localhost ...]
OLLAMA_CONTEXT_LENGTH=4096
OLLAMA_DEBUG=INFO
```

---

*æ­¤é…ç½®å·²æˆåŠŸå•Ÿç”¨ Ollama Docker å®¹å™¨çš„ GPU åŠ é€ŸåŠŸèƒ½ï¼Œå¤§å¹…æå‡äº†å¤§å‹èªè¨€æ¨¡å‹çš„æ¨ç†æ•ˆèƒ½ã€‚* 