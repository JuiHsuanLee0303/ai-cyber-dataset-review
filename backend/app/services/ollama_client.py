import httpx
import os
import json
from typing import List, Dict, Any, Optional

# OLLAMA_HOST = os.environ.get("OLLAMA_HOST", "http://ollama:11434")
OLLAMA_HOST = "http://localhost:11434"

# JSON Schema for structured outputs
DATASET_SCHEMA = {
    "type": "object",
    "properties": {
        "instruction": {
            "type": "string",
            "description": "æ˜ç¢ºçš„æŒ‡ä»¤å…§å®¹ï¼Œè¦æ±‚æ¨¡å‹å›ç­”è³‡å®‰ç›¸é—œå•é¡Œ"
        },
        "input": {
            "type": "string", 
            "description": "è¼¸å…¥å…§å®¹ï¼ˆä½¿ç”¨è€…çš„å•é¡Œæˆ–éœ€æ±‚ï¼‰"
        },
        "output": {
            "type": "string",
            "description": "æœŸæœ›çš„è¼¸å‡ºå…§å®¹ï¼Œæº–ç¢ºã€å¯¦ç”¨ä¸”ä¾ç…§æ³•è¦ä¾æ“šå›ç­”"
        },
        "history": {
            "type": "array",
            "items": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "minItems": 0,
                "description": "å°è©±æ­·å²ï¼Œæ ¼å¼ç‚º [æŒ‡ä»¤, å›ç­”]"
            },
            "description": "å°è©±ç´€éŒ„ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰"
        }
    },
    "required": ["instruction", "output"]
}

class OllamaClient:
    def __init__(self, host: str = OLLAMA_HOST, model: str = "llama3"):
        self.host = host
        self.model = model
        self.client = httpx.AsyncClient(base_url=self.host, timeout=300.0)  # å¢åŠ åˆ° 5 åˆ†é˜

    async def generate(self, prompt: str, history: List[Dict[str, Any]] = None, format_schema: Optional[Dict] = None) -> str:
        """
        Generates content using the Ollama API with optional structured output.
        
        Args:
            prompt: The input prompt
            history: Chat history
            format_schema: Optional JSON schema for structured output
        """
        full_prompt = prompt
        chat_history = []

        if history:
            for item in history:
                chat_history.append({
                    "role": item["role"],
                    "content": item["content"]
                })
        
        # Always add the current prompt as a user message
        chat_history.append({"role": "user", "content": full_prompt})

        payload = {
            "model": self.model,
            "messages": chat_history,
            "stream": False,
            "think": False
        }
        
        # Add format parameter if schema is provided
        if format_schema:
            payload["format"] = "json"
            payload["options"] = {
                "json_schema": format_schema
            }

        print(payload)

        try:
            print(f"Sending request to Ollama with prompt: {full_prompt[:200]}...")
            response = await self.client.post("/api/chat", json=payload)
            response.raise_for_status()
            
            data = response.json()
            print("Received response from Ollama.")
            print(data)
            
            # Extract content from the response
            if "message" in data and "content" in data["message"]:
                return data["message"]["content"].strip()
            elif "response" in data:
                return data["response"].strip()
            else:
                return ""
            
        except httpx.HTTPStatusError as e:
            print(f"Error response {e.response.status_code} while requesting {e.request.url!r}.")
            # Handle specific errors if needed
            return f"Error: Could not get a response from Ollama. Status: {e.response.status_code}"
        except httpx.RequestError as e:
            print(f"An error occurred while requesting {e.request.url!r}.")
            return f"Error: Could not connect to Ollama. Details: {e}"

    async def generate_structured_dataset(self, 
                                        instruction: str, 
                                        input_text: Optional[str] = None,
                                        system_prompt: Optional[str] = None,
                                        source: Optional[List[str]] = None,
                                        rejection_reasons: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        Generates a structured instruction tuning dataset using optimized prompt engineering.
        Returns a dictionary with instruction, input, and output fields.
        """
        
        # Build the optimized prompt with all context
        prompt_parts = []
        
        # 1. System context and role definition
        system_context = """ä½ æ˜¯ä¸€ä½è³‡å®‰å°ˆå®¶ï¼Œå°ˆé–€å”åŠ©ç”Ÿæˆé«˜å“è³ªçš„æŒ‡ä»¤å¾®èª¿è³‡æ–™é›†ã€‚ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šæä¾›çš„æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆç¬¦åˆè³‡å®‰æ³•è¦è¦æ±‚çš„è¨“ç·´è³‡æ–™ã€‚

è«‹åš´æ ¼æŒ‰ç…§æŒ‡å®šçš„ JSON æ ¼å¼è¼¸å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"""
        
        prompt_parts.append(system_context)
        
        # 2. Original instruction and input
        prompt_parts.append("## åŸå§‹éœ€æ±‚")
        prompt_parts.append(f"æŒ‡ä»¤: {instruction}")
        if input_text:
            prompt_parts.append(f"è¼¸å…¥: {input_text}")
        
        # 3. System prompt if provided
        if system_prompt:
            prompt_parts.append(f"ç³»çµ±æç¤º: {system_prompt}")
        
        # 4. Source regulations
        if source and len(source) > 0:
            prompt_parts.append("## æ³•è¦ä¾æ“š")
            for i, src in enumerate(source, 1):
                prompt_parts.append(f"{i}. {src}")
        
        # 5. Rejection reasons if provided
        if rejection_reasons and len(rejection_reasons) > 0:
            prompt_parts.append("## éœ€è¦æ”¹é€²çš„åœ°æ–¹")
            for i, reason in enumerate(rejection_reasons, 1):
                prompt_parts.append(f"{i}. {reason}")
        
        # 6. Final instruction
        prompt_parts.append("## ç”Ÿæˆè¦æ±‚")
        prompt_parts.append("è«‹æ ¹æ“šä¸Šè¿°è³‡è¨Šï¼Œç”Ÿæˆä¸€å€‹å®Œæ•´çš„æŒ‡ä»¤å¾®èª¿è³‡æ–™é›†é …ç›®ã€‚ç¢ºä¿ï¼š")
        prompt_parts.append("1. æŒ‡ä»¤æ¸…æ¥šæ˜ç¢ºï¼Œè¦æ±‚æ¨¡å‹å›ç­”è³‡å®‰ç›¸é—œå•é¡Œ")
        prompt_parts.append("2. è¼¸å…¥å…§å®¹æä¾›é©ç•¶çš„ä¸Šä¸‹æ–‡ï¼Œæå‡ºèˆ‡æ³•è¦ä¾æ“šç›¸é—œä½†ä¸ç›´æ¥è©¢å•æ³•è¦å…§å®¹çš„å•é¡Œ")
        prompt_parts.append("3. è¼¸å‡ºå…§å®¹æº–ç¢ºã€å¯¦ç”¨ä¸”ä¾ç…§æ³•è¦ä¾æ“šå›ç­”")
        prompt_parts.append("4. å¦‚æœæä¾›äº†æ‹’çµ•åŸå› ï¼Œè«‹é‡å°é€™äº›å•é¡Œæ”¹é€²åŸå§‹éœ€æ±‚")
        prompt_parts.append("5. è«‹ä»¥ç¹é«”ä¸­æ–‡å›ç­”")

        # 7. One Shot Prompt
        prompt_parts.append("## One Shot Prompt")
        prompt_parts.append("åˆ©ç”¨è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢ï¼šç‚ºæå‡è³‡é€šå®‰å…¨ï¼Œæ”¿åºœæ‡‰æä¾›è³‡æºï¼Œæ•´åˆæ°‘é–“åŠç”¢æ¥­åŠ›é‡ï¼Œæå‡å…¨æ°‘è³‡é€šå®‰å…¨æ„è­˜ï¼Œä¸¦æ¨å‹•ä¸‹åˆ—äº‹é …ï¼š\nä¸€ã€è³‡é€šå®‰å…¨å°ˆæ¥­äººæ‰ä¹‹åŸ¹è‚²ã€‚\näºŒã€è³‡é€šå®‰å…¨ç§‘æŠ€ä¹‹ç ”ç™¼ã€æ•´åˆã€æ‡‰ç”¨ã€ç”¢å­¸åˆä½œåŠåœ‹éš›äº¤æµåˆä½œã€‚\nä¸‰ã€è³‡é€šå®‰å…¨ç”¢æ¥­ä¹‹ç™¼å±•ã€‚\nå››ã€è³‡é€šå®‰å…¨è»Ÿç¡¬é«”æŠ€è¡“è¦ç¯„ã€ç›¸é—œæœå‹™èˆ‡å¯©é©—æ©Ÿåˆ¶ä¹‹ç™¼å±•ã€‚\nå‰é …ç›¸é—œäº‹é …ä¹‹æ¨å‹•ï¼Œç”±ä¸»ç®¡æ©Ÿé—œä»¥åœ‹å®¶è³‡é€šå®‰å…¨ç™¼å±•æ–¹æ¡ˆå®šä¹‹ã€‚")
        prompt_parts.append("è«‹æ ¹æ“šä¸Šè¿°æ³•è¦ï¼Œç”Ÿæˆçš„æŒ‡ä»¤å¾®èª¿è³‡æ–™é›†å¦‚ä¸‹ï¼š")
        prompt_parts.append("""\"instruction\": "æ”¿åºœæœƒæ€éº¼æå‡å¤§å®¶çš„è³‡å®‰èƒ½åŠ›ï¼Ÿ",
\"input\": "æ”¿åºœæœƒåšä»€éº¼ä¾†ä¿è­·æˆ‘å€‘çš„è³‡å®‰ï¼Ÿ",
\"output\": "æ”¿åºœæœƒåšçš„äº‹åŒ…æ‹¬ï¼šåŸ¹é¤Šè³‡å®‰äººæ‰ã€æ¨å‹•è³‡å®‰æŠ€è¡“ç ”ç™¼ã€ç™¼å±•è³‡å®‰ç”¢æ¥­ï¼Œä»¥åŠå»ºç«‹è³‡å®‰ç”¢å“èˆ‡æœå‹™çš„æ¨™æº–å’Œå¯©æŸ¥åˆ¶åº¦ã€‚",
\"history\": [
  ["ä»€éº¼æ˜¯è³‡é€šç³»çµ±ã€è³‡é€šå®‰å…¨å’Œè³‡é€šå®‰å…¨äº‹ä»¶ï¼Ÿ", "è³‡é€šç³»çµ±å°±æ˜¯åƒé›»è…¦ã€ä¼ºæœå™¨é€™äº›ç”¨ä¾†è™•ç†è³‡æ–™çš„ç³»çµ±ã€‚è³‡é€šå®‰å…¨æ˜¯ä¿è­·é€™äº›ç³»çµ±ä¸è¢«é§­å®¢å…¥ä¾µæˆ–è³‡æ–™è¢«å·ã€‚è³‡é€šå®‰å…¨äº‹ä»¶æ˜¯æŒ‡ç³»çµ±è¢«æ”»æ“Šã€å‡ºéŒ¯æˆ–é€ æˆæœå‹™ä¸­æ–·çš„æƒ…æ³ã€‚"]
]""")
        
        # Combine all parts
        full_prompt = "\n\n".join(prompt_parts)
        
        try:
            # Use structured output with JSON schema
            response = await self.generate(full_prompt, format_schema=DATASET_SCHEMA)
            
            # Parse JSON response
            try:
                # Try to parse the response as JSON
                result = json.loads(response)
                
                # Ensure all required fields are present
                if "instruction" not in result:
                    result["instruction"] = instruction
                if "input" not in result:
                    result["input"] = input_text or ""
                if "output" not in result:
                    result["output"] = "ç„¡æ³•ç”Ÿæˆè¼¸å‡ºå…§å®¹"
                if "history" not in result:
                    result["history"] = []
                
                # é©—è­‰å’Œä¿®æ­£ history æ ¼å¼
                if "history" in result and isinstance(result["history"], list):
                    corrected_history = []
                    for item in result["history"]:
                        if isinstance(item, list) and len(item) == 2:
                            # æ­£ç¢ºçš„äºŒç¶­é™£åˆ—æ ¼å¼
                            corrected_history.append(item)
                        elif isinstance(item, str):
                            # å¦‚æœæ˜¯å­—ä¸²ï¼Œå¯èƒ½æ˜¯å–®ä¸€å•é¡Œæˆ–å›ç­”ï¼Œè·³é
                            continue
                        elif isinstance(item, dict):
                            # å¦‚æœæ˜¯ç‰©ä»¶ï¼Œå˜—è©¦æå–å•é¡Œå’Œå›ç­”
                            if "question" in item and "answer" in item:
                                corrected_history.append([item["question"], item["answer"]])
                            elif "instruction" in item and "output" in item:
                                corrected_history.append([item["instruction"], item["output"]])
                            else:
                                # ç„¡æ³•è§£æçš„æ ¼å¼ï¼Œè·³é
                                continue
                        else:
                            # å…¶ä»–æ ¼å¼ï¼Œè·³é
                            continue
                    result["history"] = corrected_history
                else:
                    result["history"] = []
                
                return result
                
            except json.JSONDecodeError as e:
                print(f"JSON parsing error: {e}")
                print(f"Raw response: {response}")
                
                # Fallback: return structured response
                return {
                    "instruction": instruction,
                    "input": input_text or "",
                    "output": response.strip(),
                    "history": []
                }
                
        except Exception as e:
            print(f"Generation error: {e}")
            raise e

    async def generate_from_regulations(self, article_contents: List[str]) -> Dict[str, Any]:
        """
        Generate a complete dataset from legal regulations using generate_structured_dataset.
        Returns a dictionary with instruction, input, output, system, history, and source fields.
        """
        
        prompt = []
        prompt.append("ä½ æ˜¯ä¸€ä½è³‡å®‰å°ˆå®¶ï¼Œå°ˆé–€å”åŠ©ç”Ÿæˆé«˜å“è³ªçš„æŒ‡ä»¤å¾®èª¿è³‡æ–™é›†ã€‚ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šæä¾›çš„æ³•å¾‹æ¢æ–‡ï¼Œç”Ÿæˆç¬¦åˆè³‡å®‰æ³•è¦è¦æ±‚çš„è¨“ç·´è³‡æ–™ã€‚")
        prompt.append("è«‹æ ¹æ“šä»¥ä¸‹æä¾›çš„æ³•å¾‹æ¢æ–‡ï¼Œæ’°å¯«ç›¸å°æ‡‰çš„å•ç­”é›†ï¼š")
        prompt.append("## æ³•å¾‹æ¢æ–‡")
        for i, article in enumerate(article_contents, 1):
            prompt.append(f"{i}. {article}")
        prompt.append("## ç”Ÿæˆè¦æ±‚")
        prompt.append("è«‹æ ¹æ“šä¸Šè¿°è³‡è¨Šï¼Œç”Ÿæˆä¸€å€‹å®Œæ•´çš„æŒ‡ä»¤å¾®èª¿è³‡æ–™é›†é …ç›®ã€‚ç¢ºä¿ï¼š")
        prompt.append("1. æŒ‡ä»¤æ¸…æ¥šæ˜ç¢ºï¼Œè¦æ±‚æ¨¡å‹å›ç­”è³‡å®‰ç›¸é—œå•é¡Œ")
        prompt.append("2. è¼¸å…¥å…§å®¹æä¾›é©ç•¶çš„ä¸Šä¸‹æ–‡ï¼Œæå‡ºèˆ‡æ³•è¦ä¾æ“šç›¸é—œä½†ä¸ç›´æ¥è©¢å•æ³•è¦å…§å®¹çš„å•é¡Œ")
        prompt.append("3. è¼¸å‡ºå…§å®¹æº–ç¢ºã€å¯¦ç”¨ä¸”ä¾ç…§æ³•è¦ä¾æ“šå›ç­”")
        prompt.append("4. å¦‚æœæä¾›äº†æ‹’çµ•åŸå› ï¼Œè«‹é‡å°é€™äº›å•é¡Œæ”¹é€²åŸå§‹éœ€æ±‚")
        prompt.append("5. è«‹ä»¥ç¹é«”ä¸­æ–‡å›ç­”")
        prompt.append("## One Shot Prompt")
        prompt.append("åˆ©ç”¨è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢ï¼šç‚ºæå‡è³‡é€šå®‰å…¨ï¼Œæ”¿åºœæ‡‰æä¾›è³‡æºï¼Œæ•´åˆæ°‘é–“åŠç”¢æ¥­åŠ›é‡ï¼Œæå‡å…¨æ°‘è³‡é€šå®‰å…¨æ„è­˜ï¼Œä¸¦æ¨å‹•ä¸‹åˆ—äº‹é …ï¼š\nä¸€ã€è³‡é€šå®‰å…¨å°ˆæ¥­äººæ‰ä¹‹åŸ¹è‚²ã€‚\näºŒã€è³‡é€šå®‰å…¨ç§‘æŠ€ä¹‹ç ”ç™¼ã€æ•´åˆã€æ‡‰ç”¨ã€ç”¢å­¸åˆä½œåŠåœ‹éš›äº¤æµåˆä½œã€‚\nä¸‰ã€è³‡é€šå®‰å…¨ç”¢æ¥­ä¹‹ç™¼å±•ã€‚\nå››ã€è³‡é€šå®‰å…¨è»Ÿç¡¬é«”æŠ€è¡“è¦ç¯„ã€ç›¸é—œæœå‹™èˆ‡å¯©é©—æ©Ÿåˆ¶ä¹‹ç™¼å±•ã€‚\nå‰é …ç›¸é—œäº‹é …ä¹‹æ¨å‹•ï¼Œç”±ä¸»ç®¡æ©Ÿé—œä»¥åœ‹å®¶è³‡é€šå®‰å…¨ç™¼å±•æ–¹æ¡ˆå®šä¹‹ã€‚")
        prompt.append("è«‹æ ¹æ“šä¸Šè¿°æ³•è¦ï¼Œç”Ÿæˆçš„æŒ‡ä»¤å¾®èª¿è³‡æ–™é›†å¦‚ä¸‹ï¼š")
        prompt.append("""\"instruction\": "æ”¿åºœæœƒæ€éº¼æå‡å¤§å®¶çš„è³‡å®‰èƒ½åŠ›ï¼Ÿ",
\"input\": "æ”¿åºœæœƒåšä»€éº¼ä¾†ä¿è­·æˆ‘å€‘çš„è³‡å®‰ï¼Ÿ",
\"output\": "æ”¿åºœæœƒåšçš„äº‹åŒ…æ‹¬ï¼šåŸ¹é¤Šè³‡å®‰äººæ‰ã€æ¨å‹•è³‡å®‰æŠ€è¡“ç ”ç™¼ã€ç™¼å±•è³‡å®‰ç”¢æ¥­ï¼Œä»¥åŠå»ºç«‹è³‡å®‰ç”¢å“èˆ‡æœå‹™çš„æ¨™æº–å’Œå¯©æŸ¥åˆ¶åº¦ã€‚",
\"history\": [
  ["ä»€éº¼æ˜¯è³‡é€šç³»çµ±ã€è³‡é€šå®‰å…¨å’Œè³‡é€šå®‰å…¨äº‹ä»¶ï¼Ÿ", "è³‡é€šç³»çµ±å°±æ˜¯åƒé›»è…¦ã€ä¼ºæœå™¨é€™äº›ç”¨ä¾†è™•ç†è³‡æ–™çš„ç³»çµ±ã€‚è³‡é€šå®‰å…¨æ˜¯ä¿è­·é€™äº›ç³»çµ±ä¸è¢«é§­å®¢å…¥ä¾µæˆ–è³‡æ–™è¢«å·ã€‚è³‡é€šå®‰å…¨äº‹ä»¶æ˜¯æŒ‡ç³»çµ±è¢«æ”»æ“Šã€å‡ºéŒ¯æˆ–é€ æˆæœå‹™ä¸­æ–·çš„æƒ…æ³ã€‚"]
]""")

        full_prompt = "\n\n".join(prompt)
        
        try:
            # Use structured output with JSON schema
            response = await self.generate(full_prompt, format_schema=DATASET_SCHEMA)
            print(response)
            
            # Parse JSON response
            try:
                # Try to parse the response as JSON
                result = json.loads(response)
                
                # Ensure all required fields are present
                if "instruction" not in result:
                    result["instruction"] = "è«‹æ ¹æ“šè³‡å®‰æ³•è¦å›ç­”å•é¡Œ"
                if "input" not in result:
                    result["input"] = "è«‹æä¾›è³‡å®‰ç›¸é—œçš„æŒ‡å°"
                if "output" not in result:
                    result["output"] = "ç„¡æ³•ç”Ÿæˆè¼¸å‡ºå…§å®¹"
                if "history" not in result:
                    result["history"] = []
                
                # é©—è­‰å’Œä¿®æ­£ history æ ¼å¼
                if "history" in result and isinstance(result["history"], list):
                    corrected_history = []
                    for item in result["history"]:
                        if isinstance(item, list) and len(item) == 2:
                            # æ­£ç¢ºçš„äºŒç¶­é™£åˆ—æ ¼å¼
                            corrected_history.append(item)
                        elif isinstance(item, str):
                            # å¦‚æœæ˜¯å­—ä¸²ï¼Œå¯èƒ½æ˜¯å–®ä¸€å•é¡Œæˆ–å›ç­”ï¼Œè·³é
                            continue
                        elif isinstance(item, dict):
                            # å¦‚æœæ˜¯ç‰©ä»¶ï¼Œå˜—è©¦æå–å•é¡Œå’Œå›ç­”
                            if "question" in item and "answer" in item:
                                corrected_history.append([item["question"], item["answer"]])
                            elif "instruction" in item and "output" in item:
                                corrected_history.append([item["instruction"], item["output"]])
                            else:
                                # ç„¡æ³•è§£æçš„æ ¼å¼ï¼Œè·³é
                                continue
                        else:
                            # å…¶ä»–æ ¼å¼ï¼Œè·³é
                            continue
                    result["history"] = corrected_history
                else:
                    result["history"] = []
                
                return result
                
            except json.JSONDecodeError as e:
                print(f"JSON parsing error: {e}")
                print(f"Raw response: {response}")
                
                # Fallback: return structured response
                return {
                    "instruction": "è«‹æ ¹æ“šè³‡å®‰æ³•è¦å›ç­”å•é¡Œ",
                    "input": "è«‹æä¾›è³‡å®‰ç›¸é—œçš„æŒ‡å°",
                    "output": response.strip(),
                    "history": []
                }
            
        except Exception as e:
            print(f"Generation error: {e}")
            raise e

# Example of how to use it (optional, for direct testing)
async def main():
    client = OllamaClient(model="qwen3:1.7b")
    
    print("ğŸš€ é–‹å§‹æ¸¬è©¦ Ollama å®¢æˆ¶ç«¯æ‰€æœ‰åŠŸèƒ½")
    print("=" * 60)
    
    # æ¸¬è©¦ 1: åŸºæœ¬å°è©±ï¼ˆç„¡çµæ§‹åŒ–è¼¸å‡ºï¼‰
    print("\nğŸ” æ¸¬è©¦ 1: åŸºæœ¬å°è©±ï¼ˆç„¡çµæ§‹åŒ–è¼¸å‡ºï¼‰")
    print("-" * 40)
    try:
        response = await client.generate("Why is the sky blue?")
        print(f"âœ… åŸºæœ¬å°è©±æˆåŠŸ")
        print(f"å›æ‡‰: {response[:100]}...")
    except Exception as e:
        print(f"âŒ åŸºæœ¬å°è©±å¤±æ•—: {e}")
    
    # æ¸¬è©¦ 2: çµæ§‹åŒ–è¼¸å‡º
    print("\nğŸ” æ¸¬è©¦ 2: çµæ§‹åŒ–è¼¸å‡º")
    print("-" * 40)
    simple_schema = {
        "type": "object",
        "properties": {
            "question": {
                "type": "string",
                "description": "å•é¡Œå…§å®¹"
            },
            "answer": {
                "type": "string", 
                "description": "ç­”æ¡ˆå…§å®¹"
            },
            "explanation": {
                "type": "string",
                "description": "è©³ç´°è§£é‡‹"
            }
        },
        "required": ["question", "answer", "explanation"]
    }
    
    try:
        structured_response = await client.generate(
            "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼šå¤©ç©ºç‚ºä»€éº¼æ˜¯è—è‰²çš„ï¼Ÿè«‹æä¾›å•é¡Œã€ç­”æ¡ˆå’Œè©³ç´°è§£é‡‹ã€‚",
            format_schema=simple_schema
        )
        print(f"âœ… çµæ§‹åŒ–è¼¸å‡ºè«‹æ±‚æˆåŠŸ")
        print(f"åŸå§‹å›æ‡‰: {structured_response}")
        
        # å˜—è©¦è§£æ JSON
        try:
            parsed = json.loads(structured_response)
            print("âœ… JSON è§£ææˆåŠŸï¼")
            print("ğŸ“Š è§£æçµæœ:")
            print(json.dumps(parsed, ensure_ascii=False, indent=2))
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±æ•—: {e}")
            print("é€™å¯èƒ½è¡¨ç¤ºæ¨¡å‹æ²’æœ‰å®Œå…¨éµå¾ª schema")
    except Exception as e:
        print(f"âŒ çµæ§‹åŒ–è¼¸å‡ºå¤±æ•—: {e}")
    
    # æ¸¬è©¦ 3: generate_structured_dataset æ–¹æ³•
    print("\nğŸ” æ¸¬è©¦ 3: generate_structured_dataset æ–¹æ³•")
    print("-" * 40)
    try:
        result = await client.generate_structured_dataset(
            instruction="è«‹è§£é‡‹æ”¿åºœå¦‚ä½•æå‡è³‡å®‰èƒ½åŠ›",
            input_text="æ”¿åºœæœƒåšä»€éº¼ä¾†ä¿è­·æˆ‘å€‘çš„è³‡å®‰ï¼Ÿ",
            system_prompt="ä½ æ˜¯ä¸€ä½è³‡å®‰å°ˆå®¶",
            source=["è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢"],
            rejection_reasons=["å›ç­”ä¸å¤ å…·é«”", "ç¼ºä¹å¯¦ç”¨æ€§"]
        )
        print("âœ… generate_structured_dataset æˆåŠŸï¼")
        print("ğŸ“Š çµæœ:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        print(f"âŒ generate_structured_dataset å¤±æ•—: {e}")
    
    # æ¸¬è©¦ 4: generate_from_regulations æ–¹æ³•
    print("\nğŸ” æ¸¬è©¦ 4: generate_from_regulations æ–¹æ³•")
    print("-" * 40)
    regulations = [
        "è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢ï¼šç‚ºæå‡è³‡é€šå®‰å…¨ï¼Œæ”¿åºœæ‡‰æä¾›è³‡æºï¼Œæ•´åˆæ°‘é–“åŠç”¢æ¥­åŠ›é‡ï¼Œæå‡å…¨æ°‘è³‡é€šå®‰å…¨æ„è­˜ï¼Œä¸¦æ¨å‹•ä¸‹åˆ—äº‹é …ï¼šä¸€ã€è³‡é€šå®‰å…¨å°ˆæ¥­äººæ‰ä¹‹åŸ¹è‚²ã€‚äºŒã€è³‡é€šå®‰å…¨ç§‘æŠ€ä¹‹ç ”ç™¼ã€æ•´åˆã€æ‡‰ç”¨ã€ç”¢å­¸åˆä½œåŠåœ‹éš›äº¤æµåˆä½œã€‚ä¸‰ã€è³‡é€šå®‰å…¨ç”¢æ¥­ä¹‹ç™¼å±•ã€‚å››ã€è³‡é€šå®‰å…¨è»Ÿç¡¬é«”æŠ€è¡“è¦ç¯„ã€ç›¸é—œæœå‹™èˆ‡å¯©é©—æ©Ÿåˆ¶ä¹‹ç™¼å±•ã€‚"
    ]
    
    try:
        result = await client.generate_from_regulations(regulations)
        print("âœ… generate_from_regulations æˆåŠŸï¼")
        print("ğŸ“Š çµæœ:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        print(f"âŒ generate_from_regulations å¤±æ•—: {e}")
    
    # æ¸¬è©¦ 5: å¸¶æ­·å²è¨˜éŒ„çš„çµæ§‹åŒ–å°è©±
    print("\nğŸ” æ¸¬è©¦ 5: å¸¶æ­·å²è¨˜éŒ„çš„çµæ§‹åŒ–å°è©±")
    print("-" * 40)
    
    # æº–å‚™æ­·å²è¨˜éŒ„
    history = [
        {"role": "user", "content": "ä»€éº¼æ˜¯è³‡å®‰ï¼Ÿ"},
        {"role": "assistant", "content": "è³‡å®‰æ˜¯è³‡è¨Šå®‰å…¨çš„ç°¡ç¨±ï¼ŒæŒ‡ä¿è­·è³‡è¨Šç³»çµ±ã€ç¶²è·¯å’Œè³‡æ–™å…å—æœªç¶“æˆæ¬Šçš„å­˜å–ã€ä½¿ç”¨ã€æ­éœ²ã€ä¸­æ–·ã€ä¿®æ”¹æˆ–ç ´å£ã€‚"},
        {"role": "user", "content": "è³‡å®‰æœ‰å“ªäº›ä¸»è¦å¨è„…ï¼Ÿ"},
        {"role": "assistant", "content": "è³‡å®‰ä¸»è¦å¨è„…åŒ…æ‹¬ï¼šæƒ¡æ„è»Ÿé«”ã€ç¶²è·¯é‡£é­šã€è³‡æ–™å¤–æ´©ã€DDoSæ”»æ“Šã€å…§éƒ¨å¨è„…ç­‰ã€‚"}
    ]
    
    # å‰µå»ºå°ˆé–€çš„ schema ä¾†è™•ç†å¸¶æ­·å²è¨˜éŒ„çš„çµæ§‹åŒ–è¼¸å‡º
    history_schema = {
        "type": "object",
        "properties": {
            "instruction": {
                "type": "string",
                "description": "ç•¶å‰ç”¨æˆ¶çš„æŒ‡ä»¤"
            },
            "input": {
                "type": "string", 
                "description": "ç•¶å‰ç”¨æˆ¶çš„è¼¸å…¥"
            },
            "output": {
                "type": "string",
                "description": "æ¨¡å‹çš„å›ç­”"
            },
            "history": {
                "type": "array",
                "items": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "minItems": 2,
                    "maxItems": 2,
                    "description": "æ­·å²å°è©±ï¼Œæ ¼å¼ç‚º [ç”¨æˆ¶å•é¡Œ, åŠ©æ‰‹å›ç­”]"
                },
                "description": "ä¹‹å‰çš„å°è©±è¨˜éŒ„"
            },
            "context_summary": {
                "type": "string",
                "description": "åŸºæ–¼æ­·å²è¨˜éŒ„çš„ä¸Šä¸‹æ–‡æ‘˜è¦"
            }
        },
        "required": ["instruction", "output", "history"]
    }
    
    try:
        response = await client.generate(
            "åŸºæ–¼æˆ‘å€‘ä¹‹å‰çš„å°è©±ï¼Œè«‹è©³ç´°èªªæ˜è³‡å®‰çš„é‡è¦æ€§ï¼Œä¸¦æä¾›å…·é«”çš„é˜²è­·å»ºè­°ã€‚",
            history=history,
            format_schema=history_schema
        )
        print("âœ… å¸¶æ­·å²è¨˜éŒ„çš„çµæ§‹åŒ–å°è©±æˆåŠŸï¼")
        print("ğŸ“„ åŸå§‹å›æ‡‰:")
        print(response)
        print()
        
        # å˜—è©¦è§£æ JSON
        try:
            parsed = json.loads(response)
            print("âœ… JSON è§£ææˆåŠŸï¼")
            print("ğŸ“Š è§£æçµæœ:")
            print(json.dumps(parsed, ensure_ascii=False, indent=2))
            
            # é©—è­‰æ­·å²è¨˜éŒ„æ ¼å¼
            print("\nğŸ” æ­·å²è¨˜éŒ„é©—è­‰:")
            if "history" in parsed and isinstance(parsed["history"], list):
                print(f"âœ… æ­·å²è¨˜éŒ„æ•¸é‡: {len(parsed['history'])}")
                for i, item in enumerate(parsed["history"]):
                    if isinstance(item, list) and len(item) == 2:
                        print(f"âœ… history[{i}]: [å•é¡Œ, å›ç­”] æ ¼å¼æ­£ç¢º")
                        print(f"   å•é¡Œ: {item[0][:50]}...")
                        print(f"   å›ç­”: {item[1][:50]}...")
                    else:
                        print(f"âŒ history[{i}] æ ¼å¼éŒ¯èª¤")
            
            # é©—è­‰ä¸Šä¸‹æ–‡æ‘˜è¦
            if "context_summary" in parsed:
                print(f"âœ… ä¸Šä¸‹æ–‡æ‘˜è¦: {parsed['context_summary'][:100]}...")
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±æ•—: {e}")
            print("é€™å¯èƒ½è¡¨ç¤ºæ¨¡å‹æ²’æœ‰å®Œå…¨éµå¾ª schema")
    
    except Exception as e:
        print(f"âŒ å¸¶æ­·å²è¨˜éŒ„çš„çµæ§‹åŒ–å°è©±å¤±æ•—: {e}")
    
    # æ¸¬è©¦ 5.1: ä½¿ç”¨ DATASET_SCHEMA çš„æ­·å²è¨˜éŒ„æ¸¬è©¦
    print("\nğŸ” æ¸¬è©¦ 5.1: ä½¿ç”¨ DATASET_SCHEMA çš„æ­·å²è¨˜éŒ„æ¸¬è©¦")
    print("-" * 40)
    
    try:
        response = await client.generate(
            "è«‹æ ¹æ“šæˆ‘å€‘çš„å°è©±æ­·å²ï¼Œç”Ÿæˆä¸€å€‹å®Œæ•´çš„è³‡å®‰å•ç­”é›†ã€‚",
            history=history,
            format_schema=DATASET_SCHEMA
        )
        print("âœ… DATASET_SCHEMA æ­·å²è¨˜éŒ„æ¸¬è©¦æˆåŠŸï¼")
        print("ğŸ“„ åŸå§‹å›æ‡‰:")
        print(response)
        print()
        
        # å˜—è©¦è§£æ JSON
        try:
            parsed = json.loads(response)
            print("âœ… JSON è§£ææˆåŠŸï¼")
            print("ğŸ“Š è§£æçµæœ:")
            print(json.dumps(parsed, ensure_ascii=False, indent=2))
            
            # é©—è­‰ DATASET_SCHEMA æ ¼å¼
            print("\nğŸ” DATASET_SCHEMA æ ¼å¼é©—è­‰:")
            required_fields = ["instruction", "output"]
            for field in required_fields:
                if field in parsed:
                    print(f"âœ… {field} æ¬„ä½å­˜åœ¨")
                else:
                    print(f"âŒ {field} æ¬„ä½ç¼ºå¤±")
            
            if "history" in parsed and isinstance(parsed["history"], list):
                print(f"âœ… history æ¬„ä½å­˜åœ¨ï¼ŒåŒ…å« {len(parsed['history'])} å€‹æ­·å²è¨˜éŒ„")
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±æ•—: {e}")
    
    except Exception as e:
        print(f"âŒ DATASET_SCHEMA æ­·å²è¨˜éŒ„æ¸¬è©¦å¤±æ•—: {e}")
    
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
    print("=" * 60)

if __name__ == "__main__":
    import asyncio
    asyncio.run(main()) 