# Ollama çµæ§‹åŒ–è¼¸å‡ºåŠŸèƒ½ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æœ¬å°ˆæ¡ˆå·²æ•´åˆ Ollama v0.5.0+ çš„çµæ§‹åŒ–è¼¸å‡ºåŠŸèƒ½ï¼Œé€é JSON schema ä¾†ç´„æŸæ¨¡å‹è¼¸å‡ºæ ¼å¼ï¼Œç¢ºä¿å›æ‡‰çš„ä¸€è‡´æ€§å’Œå¯é æ¸¬æ€§ã€‚

## åŠŸèƒ½ç‰¹è‰²

### âœ… æ”¯æ´çš„æ¨¡å‹
æ ¹æ“šå¯¦å‹™ç¶“é©—ï¼Œä»¥ä¸‹æ¨¡å‹å°çµæ§‹åŒ–è¼¸å‡ºæœ‰è‰¯å¥½çš„æ”¯æ´ï¼š

| æ¨¡å‹ | æ”¯æ´åº¦ | å»ºè­°ç”¨é€” |
|------|--------|----------|
| `llama3.1:8b` / `llama3.2:8b` | â­â­â­â­â­ | æœ€ä½³é¸æ“‡ï¼Œç©©å®šå¯é  |
| `qwen3:1.7b` / `qwen3:2.5b` | â­â­â­â­ | è¡¨ç¾å„ªè‰¯ï¼Œä¸­æ–‡æ”¯æ´å¥½ |
| `gemma2:9b` / `phi3:3.8b` | â­â­ | è¼ƒä¸ç©©å®šï¼Œéœ€è¦é©—è­‰ |

### ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

1. **JSON Schema é©—è­‰**ï¼šä½¿ç”¨é å®šç¾©çš„ schema ç¢ºä¿è¼¸å‡ºæ ¼å¼
2. **è‡ªå‹•å›é€€æ©Ÿåˆ¶**ï¼šç•¶çµæ§‹åŒ–è¼¸å‡ºå¤±æ•—æ™‚ï¼Œè‡ªå‹•å›é€€åˆ°å‚³çµ±è§£æ
3. **å¤šç¨®ç”Ÿæˆæ–¹æ³•**ï¼šæ”¯æ´ä¸åŒå ´æ™¯çš„è³‡æ–™é›†ç”Ÿæˆéœ€æ±‚

## ä½¿ç”¨æ–¹æ³•

### 1. åŸºæœ¬çµæ§‹åŒ–è¼¸å‡º

```python
from app.services.ollama_client import OllamaClient

# åˆå§‹åŒ–å®¢æˆ¶ç«¯
client = OllamaClient(model="qwen3:1.7b")

# å®šç¾©è‡ªå®šç¾© schema
custom_schema = {
    "type": "object",
    "properties": {
        "question": {"type": "string"},
        "answer": {"type": "string"},
        "confidence": {"type": "number"}
    },
    "required": ["question", "answer"]
}

# ä½¿ç”¨çµæ§‹åŒ–è¼¸å‡º
response = await client.generate(
    "è«‹å›ç­”ä»€éº¼æ˜¯è³‡å®‰ï¼Ÿ", 
    format_schema=custom_schema
)
```

### 2. ç”ŸæˆæŒ‡ä»¤å¾®èª¿è³‡æ–™é›†

```python
# ä½¿ç”¨é å®šç¾©çš„è³‡æ–™é›† schema
result = await client.generate_structured_dataset(
    instruction="è«‹è§£é‡‹æ”¿åºœå¦‚ä½•æå‡è³‡å®‰èƒ½åŠ›",
    input_text="æ”¿åºœæœƒåšä»€éº¼ä¾†ä¿è­·æˆ‘å€‘çš„è³‡å®‰ï¼Ÿ",
    system_prompt="ä½ æ˜¯ä¸€ä½è³‡å®‰å°ˆå®¶",
    source=["è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢"],
    rejection_reasons=["å›ç­”ä¸å¤ å…·é«”", "ç¼ºä¹å¯¦ç”¨æ€§"]
)

print(result)
# è¼¸å‡ºæ ¼å¼ï¼š
# {
#   "instruction": "è«‹è§£é‡‹æ”¿åºœå¦‚ä½•æå‡è³‡å®‰èƒ½åŠ›",
#   "input": "æ”¿åºœæœƒåšä»€éº¼ä¾†ä¿è­·æˆ‘å€‘çš„è³‡å®‰ï¼Ÿ",
#   "output": "æ”¿åºœæœƒåšçš„äº‹åŒ…æ‹¬ï¼šåŸ¹é¤Šè³‡å®‰äººæ‰...",
#   "history": [],
#   "system": "ä½ æ˜¯ä¸€ä½è³‡å®‰å°ˆå®¶",
#   "source": ["è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢"]
# }
```

### 3. å¾æ³•è¦ç”Ÿæˆè³‡æ–™é›†

```python
regulations = [
    "è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢ï¼šç‚ºæå‡è³‡é€šå®‰å…¨ï¼Œæ”¿åºœæ‡‰æä¾›è³‡æº..."
]

result = await client.generate_from_regulations(regulations)
```

## é å®šç¾© Schema

### DATASET_SCHEMA

ç”¨æ–¼ç”ŸæˆæŒ‡ä»¤å¾®èª¿è³‡æ–™é›†çš„æ¨™æº– schemaï¼š

```json
{
  "type": "object",
  "properties": {
    "instruction": {
      "type": "string",
      "description": "æ˜ç¢ºçš„æŒ‡ä»¤å…§å®¹ï¼Œè¦æ±‚æ¨¡å‹å›ç­”è³‡å®‰ç›¸é—œå•é¡Œ"
    },
    "input": {
      "type": "string", 
      "description": "è¼¸å…¥å…§å®¹ï¼ˆä½¿ç”¨è€…çš„å•é¡Œæˆ–éœ€æ±‚ï¼‰"
    },
    "output": {
      "type": "string",
      "description": "æœŸæœ›çš„è¼¸å‡ºå…§å®¹ï¼Œæº–ç¢ºã€å¯¦ç”¨ä¸”ä¾ç…§æ³•è¦ä¾æ“šå›ç­”"
    },
    "history": {
      "type": "array",
      "items": {"type": "string"},
      "description": "å°è©±ç´€éŒ„ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰"
    },
    "system": {
      "type": "string",
      "description": "ç³»çµ±æç¤ºè©"
    },
    "source": {
      "type": "array",
      "items": {"type": "string"},
      "description": "æ³•è¦ä¾æ“šä¾†æº"
    }
  },
  "required": ["instruction", "input", "output"]
}
```

## æ¸¬è©¦èˆ‡é©—è­‰

### é‹è¡Œæ¸¬è©¦è…³æœ¬

```bash
cd backend
python test_structured_output.py
```

æ¸¬è©¦è…³æœ¬æœƒï¼š
1. æ¸¬è©¦åŸºæœ¬çµæ§‹åŒ–è¼¸å‡ºåŠŸèƒ½
2. é©—è­‰ä¸åŒæ–¹æ³•çš„é‹ä½œ
3. æ¸¬è©¦å¤šå€‹æ¨¡å‹çš„ç›¸å®¹æ€§

### æ‰‹å‹•æ¸¬è©¦

```python
import asyncio
from app.services.ollama_client import OllamaClient

async def test():
    client = OllamaClient(model="qwen3:1.7b")
    
    # ç°¡å–®æ¸¬è©¦
    response = await client.generate(
        "ç”Ÿæˆä¸€å€‹åŒ…å«å§“åå’Œå¹´é½¡çš„ JSON", 
        format_schema={
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "age": {"type": "integer"}
            },
            "required": ["name", "age"]
        }
    )
    
    print(response)

asyncio.run(test())
```

## æœ€ä½³å¯¦è¸

### 1. æ¨¡å‹é¸æ“‡
- **æ¨è–¦**ï¼šä½¿ç”¨ `llama3.1:8b` æˆ– `qwen3:1.7b`
- **é¿å…**ï¼šGemma å’Œ Phi ç³»åˆ—ï¼ˆé™¤éç¶“éæ¸¬è©¦é©—è­‰ï¼‰

### 2. Schema è¨­è¨ˆ
- ä¿æŒ schema ç°¡æ½”æ˜ç¢º
- ä½¿ç”¨ `description` æ¬„ä½æä¾›æ¸…æ™°çš„æŒ‡å°
- åªå°‡å¿…è¦æ¬„ä½è¨­ç‚º `required`

### 3. éŒ¯èª¤è™•ç†
- ç¸½æ˜¯åŒ…å« JSON è§£æçš„éŒ¯èª¤è™•ç†
- æä¾›å›é€€æ©Ÿåˆ¶ä»¥è™•ç†çµæ§‹åŒ–è¼¸å‡ºå¤±æ•—çš„æƒ…æ³

### 4. æç¤ºè©å„ªåŒ–
- åœ¨æç¤ºè©ä¸­æ˜ç¢ºè¦æ±‚ JSON æ ¼å¼è¼¸å‡º
- æä¾›ç¯„ä¾‹ä¾†æŒ‡å°æ¨¡å‹

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **JSON è§£æéŒ¯èª¤**
   - æª¢æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æ´çµæ§‹åŒ–è¼¸å‡º
   - å˜—è©¦ä½¿ç”¨æ›´ç°¡å–®çš„ schema
   - ç¢ºèª Ollama ç‰ˆæœ¬ >= v0.5.0

2. **æ¨¡å‹å›æ‡‰ä¸ç©©å®š**
   - åˆ‡æ›åˆ° `llama3.1` æˆ– `qwen` ç³»åˆ—
   - ç°¡åŒ– schema çµæ§‹
   - å¢åŠ æç¤ºè©çš„æ˜ç¢ºæ€§

3. **é€£æ¥å•é¡Œ**
   - ç¢ºèª Ollama æœå‹™æ­£åœ¨é‹è¡Œ
   - æª¢æŸ¥é€£æ¥åœ°å€å’Œç«¯å£
   - é©—è­‰æ¨¡å‹æ˜¯å¦å·²ä¸‹è¼‰

### é™¤éŒ¯æŠ€å·§

```python
# å•Ÿç”¨è©³ç´°æ—¥èªŒ
import logging
logging.basicConfig(level=logging.DEBUG)

# æª¢æŸ¥åŸå§‹å›æ‡‰
response = await client.generate(prompt, format_schema=schema)
print(f"åŸå§‹å›æ‡‰: {response}")

# é©—è­‰ JSON æ ¼å¼
try:
    parsed = json.loads(response)
    print("JSON è§£ææˆåŠŸ")
except json.JSONDecodeError as e:
    print(f"JSON è§£æå¤±æ•—: {e}")
```

## ç‰ˆæœ¬è¦æ±‚

- Ollama >= v0.5.0
- Python >= 3.8
- httpx >= 0.24.0

## åƒè€ƒè³‡æº

- [Ollama çµæ§‹åŒ–è¼¸å‡ºå®˜æ–¹æ–‡æª”](https://ollama.com/blog/structured-outputs)
- [JSON Schema è¦ç¯„](https://json-schema.org/)
- [æ¨¡å‹ç›¸å®¹æ€§è¨è«–](https://www.reddit.com/r/LocalLLaMA/comments/1jflouy/structured_outputs_with_ollama_whats_your_recipe/) 