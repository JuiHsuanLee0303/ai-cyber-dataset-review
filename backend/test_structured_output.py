#!/usr/bin/env python3
"""
æ¸¬è©¦ Ollama çµæ§‹åŒ–è¼¸å‡ºåŠŸèƒ½çš„è…³æœ¬
"""

import asyncio
import json
from app.services.ollama_client import OllamaClient, DATASET_SCHEMA

async def test_structured_output():
    """æ¸¬è©¦çµæ§‹åŒ–è¼¸å‡ºåŠŸèƒ½"""
    
    # åˆå§‹åŒ–å®¢æˆ¶ç«¯ï¼Œä½¿ç”¨æ”¯æ´çµæ§‹åŒ–è¼¸å‡ºçš„æ¨¡å‹
    # å»ºè­°ä½¿ç”¨ llama3.1/3.2 æˆ– qwen ç³»åˆ—
    client = OllamaClient(model="qwen3:1.7b")
    
    print("ğŸ§ª é–‹å§‹æ¸¬è©¦ Ollama çµæ§‹åŒ–è¼¸å‡ºåŠŸèƒ½...")
    print(f"ğŸ“‹ ä½¿ç”¨çš„æ¨¡å‹: {client.model}")
    print(f"ğŸ”— é€£æ¥åœ°å€: {client.host}")
    print()
    
    # æ¸¬è©¦ 1: åŸºæœ¬çµæ§‹åŒ–è¼¸å‡º
    print("=" * 50)
    print("æ¸¬è©¦ 1: åŸºæœ¬çµæ§‹åŒ–è¼¸å‡º")
    print("=" * 50)
    
    test_prompt = """è«‹æ ¹æ“šè³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢ç”Ÿæˆä¸€å€‹å•ç­”é›†ï¼š

è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢ï¼šç‚ºæå‡è³‡é€šå®‰å…¨ï¼Œæ”¿åºœæ‡‰æä¾›è³‡æºï¼Œæ•´åˆæ°‘é–“åŠç”¢æ¥­åŠ›é‡ï¼Œæå‡å…¨æ°‘è³‡é€šå®‰å…¨æ„è­˜ï¼Œä¸¦æ¨å‹•ä¸‹åˆ—äº‹é …ï¼š
ä¸€ã€è³‡é€šå®‰å…¨å°ˆæ¥­äººæ‰ä¹‹åŸ¹è‚²ã€‚
äºŒã€è³‡é€šå®‰å…¨ç§‘æŠ€ä¹‹ç ”ç™¼ã€æ•´åˆã€æ‡‰ç”¨ã€ç”¢å­¸åˆä½œåŠåœ‹éš›äº¤æµåˆä½œã€‚
ä¸‰ã€è³‡é€šå®‰å…¨ç”¢æ¥­ä¹‹ç™¼å±•ã€‚
å››ã€è³‡é€šå®‰å…¨è»Ÿç¡¬é«”æŠ€è¡“è¦ç¯„ã€ç›¸é—œæœå‹™èˆ‡å¯©é©—æ©Ÿåˆ¶ä¹‹ç™¼å±•ã€‚

è«‹ç”Ÿæˆä¸€å€‹é—œæ–¼æ”¿åºœå¦‚ä½•æå‡è³‡å®‰èƒ½åŠ›çš„å•ç­”é›†ã€‚"""
    
    try:
        response = await client.generate(test_prompt, format_schema=DATASET_SCHEMA)
        print("âœ… çµæ§‹åŒ–è¼¸å‡ºæˆåŠŸï¼")
        print("ğŸ“„ åŸå§‹å›æ‡‰:")
        print(response)
        print()
        
        # å˜—è©¦è§£æ JSON
        try:
            parsed = json.loads(response)
            print("âœ… JSON è§£ææˆåŠŸï¼")
            print("ğŸ“Š è§£æçµæœ:")
            print(json.dumps(parsed, ensure_ascii=False, indent=2))
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±æ•—: {e}")
            print("é€™å¯èƒ½è¡¨ç¤ºæ¨¡å‹æ²’æœ‰å®Œå…¨éµå¾ª schema")
    
    except Exception as e:
        print(f"âŒ çµæ§‹åŒ–è¼¸å‡ºæ¸¬è©¦å¤±æ•—: {e}")
    
    print()
    
    # æ¸¬è©¦ 2: ä½¿ç”¨ generate_structured_dataset æ–¹æ³•
    print("=" * 50)
    print("æ¸¬è©¦ 2: generate_structured_dataset æ–¹æ³•")
    print("=" * 50)
    
    try:
        result = await client.generate_structured_dataset(
            instruction="è«‹è§£é‡‹æ”¿åºœå¦‚ä½•æå‡è³‡å®‰èƒ½åŠ›",
            input_text="æ”¿åºœæœƒåšä»€éº¼ä¾†ä¿è­·æˆ‘å€‘çš„è³‡å®‰ï¼Ÿ",
            system_prompt="ä½ æ˜¯ä¸€ä½è³‡å®‰å°ˆå®¶",
            source=["è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢"],
            rejection_reasons=["å›ç­”ä¸å¤ å…·é«”", "ç¼ºä¹å¯¦ç”¨æ€§"]
        )
        
        print("âœ… generate_structured_dataset æˆåŠŸï¼")
        print("ğŸ“Š çµæœ:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
    except Exception as e:
        print(f"âŒ generate_structured_dataset æ¸¬è©¦å¤±æ•—: {e}")
    
    print()
    
    # æ¸¬è©¦ 3: ä½¿ç”¨ generate_from_regulations æ–¹æ³•
    print("=" * 50)
    print("æ¸¬è©¦ 3: generate_from_regulations æ–¹æ³•")
    print("=" * 50)
    
    regulations = [
        "è³‡é€šå®‰å…¨ç®¡ç†æ³•ç¬¬4æ¢ï¼šç‚ºæå‡è³‡é€šå®‰å…¨ï¼Œæ”¿åºœæ‡‰æä¾›è³‡æºï¼Œæ•´åˆæ°‘é–“åŠç”¢æ¥­åŠ›é‡ï¼Œæå‡å…¨æ°‘è³‡é€šå®‰å…¨æ„è­˜ï¼Œä¸¦æ¨å‹•ä¸‹åˆ—äº‹é …ï¼šä¸€ã€è³‡é€šå®‰å…¨å°ˆæ¥­äººæ‰ä¹‹åŸ¹è‚²ã€‚äºŒã€è³‡é€šå®‰å…¨ç§‘æŠ€ä¹‹ç ”ç™¼ã€æ•´åˆã€æ‡‰ç”¨ã€ç”¢å­¸åˆä½œåŠåœ‹éš›äº¤æµåˆä½œã€‚ä¸‰ã€è³‡é€šå®‰å…¨ç”¢æ¥­ä¹‹ç™¼å±•ã€‚å››ã€è³‡é€šå®‰å…¨è»Ÿç¡¬é«”æŠ€è¡“è¦ç¯„ã€ç›¸é—œæœå‹™èˆ‡å¯©é©—æ©Ÿåˆ¶ä¹‹ç™¼å±•ã€‚"
    ]
    
    try:
        result = await client.generate_from_regulations(regulations)
        
        print("âœ… generate_from_regulations æˆåŠŸï¼")
        print("ğŸ“Š çµæœ:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
    except Exception as e:
        print(f"âŒ generate_from_regulations æ¸¬è©¦å¤±æ•—: {e}")
    
    print()
    print("ğŸ‰ æ¸¬è©¦å®Œæˆï¼")

async def test_model_compatibility():
    """æ¸¬è©¦ä¸åŒæ¨¡å‹çš„çµæ§‹åŒ–è¼¸å‡ºç›¸å®¹æ€§"""
    
    print("=" * 50)
    print("æ¨¡å‹ç›¸å®¹æ€§æ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦ä¸åŒçš„æ¨¡å‹
    models_to_test = [
        "qwen3:1.7b",
        "llama3.1:8b", 
        "llama3.2:8b",
        "gemma2:9b"
    ]
    
    test_prompt = "è«‹ç”Ÿæˆä¸€å€‹ç°¡å–®çš„ JSON ç‰©ä»¶ï¼ŒåŒ…å« name å’Œ age æ¬„ä½"
    
    simple_schema = {
        "type": "object",
        "properties": {
            "name": {"type": "string"},
            "age": {"type": "integer"}
        },
        "required": ["name", "age"]
    }
    
    for model in models_to_test:
        print(f"\nğŸ” æ¸¬è©¦æ¨¡å‹: {model}")
        try:
            client = OllamaClient(model=model)
            response = await client.generate(test_prompt, format_schema=simple_schema)
            
            try:
                parsed = json.loads(response)
                print(f"âœ… {model}: çµæ§‹åŒ–è¼¸å‡ºæˆåŠŸ")
                print(f"   çµæœ: {parsed}")
            except json.JSONDecodeError:
                print(f"âš ï¸  {model}: çµæ§‹åŒ–è¼¸å‡ºå¤±æ•— (JSON è§£æéŒ¯èª¤)")
                print(f"   åŸå§‹å›æ‡‰: {response[:100]}...")
                
        except Exception as e:
            print(f"âŒ {model}: è«‹æ±‚å¤±æ•— - {e}")

if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹• Ollama çµæ§‹åŒ–è¼¸å‡ºæ¸¬è©¦")
    print()
    
    # é‹è¡Œæ¸¬è©¦
    asyncio.run(test_structured_output())
    print()
    asyncio.run(test_model_compatibility()) 